{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T14:38:40.974593Z",
     "start_time": "2025-07-31T14:36:30.560242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_id = \"ModelSpace/GemmaX2-28-2B-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)"
   ],
   "id": "e0863c089ddf18fa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "147330665d0c4c17a89fd9959b4fde92"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      3\u001B[39m model_id = \u001B[33m\"\u001B[39m\u001B[33mModelSpace/GemmaX2-28-2B-v0.1\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m      4\u001B[39m tokenizer = AutoTokenizer.from_pretrained(model_id)\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m model = AutoModelForCausalLM.from_pretrained(model_id)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\common_env\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:600\u001B[39m, in \u001B[36m_BaseAutoModelClass.from_pretrained\u001B[39m\u001B[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[39m\n\u001B[32m    598\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m model_class.config_class == config.sub_configs.get(\u001B[33m\"\u001B[39m\u001B[33mtext_config\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m    599\u001B[39m         config = config.get_text_config()\n\u001B[32m--> \u001B[39m\u001B[32m600\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m model_class.from_pretrained(\n\u001B[32m    601\u001B[39m         pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs\n\u001B[32m    602\u001B[39m     )\n\u001B[32m    603\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    604\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mUnrecognized configuration class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig.\u001B[34m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m for this kind of AutoModel: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    605\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mModel type should be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m, \u001B[39m\u001B[33m'\u001B[39m.join(c.\u001B[34m__name__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mcls\u001B[39m._model_mapping.keys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    606\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\common_env\\Lib\\site-packages\\transformers\\modeling_utils.py:311\u001B[39m, in \u001B[36mrestore_default_torch_dtype.<locals>._wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    309\u001B[39m old_dtype = torch.get_default_dtype()\n\u001B[32m    310\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m311\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m func(*args, **kwargs)\n\u001B[32m    312\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    313\u001B[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\common_env\\Lib\\site-packages\\transformers\\modeling_utils.py:4839\u001B[39m, in \u001B[36mPreTrainedModel.from_pretrained\u001B[39m\u001B[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001B[39m\n\u001B[32m   4829\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m dtype_orig \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   4830\u001B[39m         torch.set_default_dtype(dtype_orig)\n\u001B[32m   4832\u001B[39m     (\n\u001B[32m   4833\u001B[39m         model,\n\u001B[32m   4834\u001B[39m         missing_keys,\n\u001B[32m   4835\u001B[39m         unexpected_keys,\n\u001B[32m   4836\u001B[39m         mismatched_keys,\n\u001B[32m   4837\u001B[39m         offload_index,\n\u001B[32m   4838\u001B[39m         error_msgs,\n\u001B[32m-> \u001B[39m\u001B[32m4839\u001B[39m     ) = \u001B[38;5;28mcls\u001B[39m._load_pretrained_model(\n\u001B[32m   4840\u001B[39m         model,\n\u001B[32m   4841\u001B[39m         state_dict,\n\u001B[32m   4842\u001B[39m         checkpoint_files,\n\u001B[32m   4843\u001B[39m         pretrained_model_name_or_path,\n\u001B[32m   4844\u001B[39m         ignore_mismatched_sizes=ignore_mismatched_sizes,\n\u001B[32m   4845\u001B[39m         sharded_metadata=sharded_metadata,\n\u001B[32m   4846\u001B[39m         device_map=device_map,\n\u001B[32m   4847\u001B[39m         disk_offload_folder=offload_folder,\n\u001B[32m   4848\u001B[39m         offload_state_dict=offload_state_dict,\n\u001B[32m   4849\u001B[39m         dtype=torch_dtype,\n\u001B[32m   4850\u001B[39m         hf_quantizer=hf_quantizer,\n\u001B[32m   4851\u001B[39m         keep_in_fp32_regex=keep_in_fp32_regex,\n\u001B[32m   4852\u001B[39m         device_mesh=device_mesh,\n\u001B[32m   4853\u001B[39m         key_mapping=key_mapping,\n\u001B[32m   4854\u001B[39m         weights_only=weights_only,\n\u001B[32m   4855\u001B[39m     )\n\u001B[32m   4857\u001B[39m \u001B[38;5;66;03m# record tp degree the model sharded to\u001B[39;00m\n\u001B[32m   4858\u001B[39m model._tp_size = tp_size\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\common_env\\Lib\\site-packages\\transformers\\modeling_utils.py:5302\u001B[39m, in \u001B[36mPreTrainedModel._load_pretrained_model\u001B[39m\u001B[34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001B[39m\n\u001B[32m   5299\u001B[39m         args_list = logging.tqdm(args_list, desc=\u001B[33m\"\u001B[39m\u001B[33mLoading checkpoint shards\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m   5301\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m args \u001B[38;5;129;01min\u001B[39;00m args_list:\n\u001B[32m-> \u001B[39m\u001B[32m5302\u001B[39m         _error_msgs, disk_offload_index, cpu_offload_index = load_shard_file(args)\n\u001B[32m   5303\u001B[39m         error_msgs += _error_msgs\n\u001B[32m   5305\u001B[39m \u001B[38;5;66;03m# Adjust offloaded weights name and save if needed\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\common_env\\Lib\\site-packages\\transformers\\modeling_utils.py:933\u001B[39m, in \u001B[36mload_shard_file\u001B[39m\u001B[34m(args)\u001B[39m\n\u001B[32m    931\u001B[39m \u001B[38;5;66;03m# Skip it with fsdp on ranks other than 0\u001B[39;00m\n\u001B[32m    932\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (is_fsdp_enabled() \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_local_dist_rank_0() \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_quantized):\n\u001B[32m--> \u001B[39m\u001B[32m933\u001B[39m     disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(\n\u001B[32m    934\u001B[39m         model_to_load,\n\u001B[32m    935\u001B[39m         state_dict,\n\u001B[32m    936\u001B[39m         shard_file,\n\u001B[32m    937\u001B[39m         expected_keys,\n\u001B[32m    938\u001B[39m         reverse_key_renaming_mapping,\n\u001B[32m    939\u001B[39m         device_map=device_map,\n\u001B[32m    940\u001B[39m         disk_offload_folder=disk_offload_folder,\n\u001B[32m    941\u001B[39m         disk_offload_index=disk_offload_index,\n\u001B[32m    942\u001B[39m         cpu_offload_folder=cpu_offload_folder,\n\u001B[32m    943\u001B[39m         cpu_offload_index=cpu_offload_index,\n\u001B[32m    944\u001B[39m         hf_quantizer=hf_quantizer,\n\u001B[32m    945\u001B[39m         is_safetensors=is_offloaded_safetensors,\n\u001B[32m    946\u001B[39m         keep_in_fp32_regex=keep_in_fp32_regex,\n\u001B[32m    947\u001B[39m         unexpected_keys=unexpected_keys,\n\u001B[32m    948\u001B[39m         device_mesh=device_mesh,\n\u001B[32m    949\u001B[39m     )\n\u001B[32m    951\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m error_msgs, disk_offload_index, cpu_offload_index\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\common_env\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001B[39m, in \u001B[36mcontext_decorator.<locals>.decorate_context\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    113\u001B[39m \u001B[38;5;129m@functools\u001B[39m.wraps(func)\n\u001B[32m    114\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdecorate_context\u001B[39m(*args, **kwargs):\n\u001B[32m    115\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[32m--> \u001B[39m\u001B[32m116\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m func(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\common_env\\Lib\\site-packages\\transformers\\modeling_utils.py:810\u001B[39m, in \u001B[36m_load_state_dict_into_meta_model\u001B[39m\u001B[34m(model, state_dict, shard_file, expected_keys, reverse_renaming_mapping, device_map, disk_offload_folder, disk_offload_index, cpu_offload_folder, cpu_offload_index, hf_quantizer, is_safetensors, keep_in_fp32_regex, unexpected_keys, device_mesh)\u001B[39m\n\u001B[32m    808\u001B[39m param = param[...]\n\u001B[32m    809\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m casting_dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m810\u001B[39m     param = param.to(casting_dtype)\n\u001B[32m    811\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m to_contiguous:\n\u001B[32m    812\u001B[39m     param = param.contiguous()\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T14:38:42.181687200Z",
     "start_time": "2025-07-29T10:51:27.542736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"\"\"Translate the following :\n",
    "Zwei Seelen wohnen, ach! in meiner Brust.\n",
    "\n",
    "Translation :\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")"
   ],
   "id": "b338850b4e513e64",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T14:38:42.496469100Z",
     "start_time": "2025-07-29T11:12:26.559453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=100,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.1,\n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ],
   "id": "671deca8a488fd3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the following :\n",
      "Zwei Seelen wohnen, ach! in meiner Brust.\n",
      "\n",
      "Translation :\n",
      "Two souls dwell, alas! in my breast.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=100,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.1,\n",
    "    top_k=5,\n",
    "    return_dict_in_generate=True,  # so we can access .sequences\n",
    ")\n",
    "\n",
    "# assume inputs[\"input_ids\"] exists and is shape (batch, seq_len)\n",
    "input_len = inputs[\"input_ids\"].shape[1]\n",
    "generated_sequences = outputs.sequences  # (batch, input_len + new_tokens)\n",
    "\n",
    "# slice off the prompt\n",
    "new_tokens = generated_sequences[:, input_len:]\n",
    "# decode only the generated part\n",
    "decoded = tokenizer.batch_decode(new_tokens, skip_special_tokens=True)\n",
    "\n",
    "# if batch size is 1, you can do:\n",
    "print(decoded[0])"
   ],
   "id": "82cd65fd18ad98f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T11:21:32.458758Z",
     "start_time": "2025-08-06T11:21:32.425147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import langdetect\n",
    "\n",
    "langdetect.DetectorFactory.seed = 0\n",
    "lang = langdetect.detect(\"War doesn't show who's right, just who's left.\")\n",
    "lang"
   ],
   "id": "2684fbbf2630d815",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "eb42430127b1a19a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
